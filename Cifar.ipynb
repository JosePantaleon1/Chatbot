{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPaGvhlNVHiNTjT2jJn6C/D",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JosePantaleon1/Chatbot/blob/main/Cifar.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lj7ePkH9lxLm"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUlM0R9mmbzV",
        "outputId": "2178c0ad-363b-4318-bc24-f69f786fdd4f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: Preprocess the Data\n",
        "We need to normalize the image data so that pixel values are between 0 and 1, which helps the model train faster and more accurately. We also convert the class labels to \"one-hot encoding\" because our model will output probabilities for each of the 10 classes."
      ],
      "metadata": {
        "id": "-QhLqj9Lo91h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize pixel values to the range [0, 1]\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "# Convert labels to one-hot encoding (e.g., \"2\" becomes [0, 0, 1, 0, ..., 0])\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n"
      ],
      "metadata": {
        "id": "snOvkWcknO64"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Build the Model\n",
        "We’ll use the Functional API to create a model with three convolutional blocks. Each block contains:\n",
        "\n",
        "A convolutional layer (Conv2D) that detects patterns in the image.\n",
        "A pooling layer (MaxPooling2D) that reduces the image size, making computations faster.\n",
        "A dropout layer (Dropout) that helps prevent overfitting.\n",
        "Finally, we flatten the data (turn it into a 1D vector) and use fully connected (Dense) layers for classification."
      ],
      "metadata": {
        "id": "W6Xwl16wpBdT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Input layer: Define the shape of the images (32x32 with 3 color channels)\n",
        "inputs = Input(shape=(32, 32, 3))\n",
        "\n",
        "# First convolutional block\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
        "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "x = Dropout(0.25)(x)\n",
        "\n",
        "# Second convolutional block\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "x = Dropout(0.25)(x)\n",
        "\n",
        "# Third convolutional block\n",
        "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "x = Dropout(0.25)(x)\n",
        "\n",
        "# Fully connected layers\n",
        "x = Flatten()(x)  # Flatten the 3D data to 1D\n",
        "x = Dense(512, activation='relu')(x)  # Dense layer with 512 neurons\n",
        "x = Dropout(0.5)(x)  # Dropout for regularization\n",
        "outputs = Dense(10, activation='softmax')(x)  # Output layer for 10 classes\n",
        "\n",
        "# Define the model\n",
        "model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "# Compile the model: Define the optimizer, loss function, and evaluation metric\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "5R1EIqxNpGlQ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Train the Model\n",
        "We train the model on the training data. We use a validation_split of 0.1, which means 10% of the training data is reserved for validation (to monitor how well the model is performing)."
      ],
      "metadata": {
        "id": "SD_oWo_dpQ0N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    x_train, y_train,  # Training data\n",
        "    validation_split=0.1,  # Use 10% of training data for validation\n",
        "    epochs=10,  # Number of passes through the entire dataset\n",
        "    batch_size=64,  # Number of samples processed before updating the model\n",
        "    verbose=1  # Show progress during training\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhQXwWRDo2ba",
        "outputId": "0dd22046-cba0-4f25-f982-1535c4fa341e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 13ms/step - accuracy: 0.3021 - loss: 1.8714 - val_accuracy: 0.5586 - val_loss: 1.2572\n",
            "Epoch 2/10\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5321 - loss: 1.3074 - val_accuracy: 0.6328 - val_loss: 1.0364\n",
            "Epoch 3/10\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5944 - loss: 1.1410 - val_accuracy: 0.6830 - val_loss: 0.9103\n",
            "Epoch 4/10\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6355 - loss: 1.0255 - val_accuracy: 0.6904 - val_loss: 0.8778\n",
            "Epoch 5/10\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.6577 - loss: 0.9589 - val_accuracy: 0.7176 - val_loss: 0.8304\n",
            "Epoch 6/10\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.6796 - loss: 0.9019 - val_accuracy: 0.7304 - val_loss: 0.7672\n",
            "Epoch 7/10\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6953 - loss: 0.8618 - val_accuracy: 0.7326 - val_loss: 0.7634\n",
            "Epoch 8/10\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.7098 - loss: 0.8194 - val_accuracy: 0.7428 - val_loss: 0.7439\n",
            "Epoch 9/10\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7249 - loss: 0.7795 - val_accuracy: 0.7510 - val_loss: 0.7258\n",
            "Epoch 10/10\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.7363 - loss: 0.7501 - val_accuracy: 0.7602 - val_loss: 0.6987\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Continue training the model for another 30 epochs\n",
        "history_fine_tune = model.fit(\n",
        "    x_train, y_train,  # Training data\n",
        "    validation_split=0.1,  # Use 10% of training data for validation\n",
        "    epochs=30,  # Additional epochs\n",
        "    batch_size=64,  # Same batch size as before\n",
        "    verbose=1  # Show progress during training\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1VSXzgCrKNA",
        "outputId": "63599aec-d445-442e-c303-6384425c04d7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7429 - loss: 0.7386 - val_accuracy: 0.7730 - val_loss: 0.6652\n",
            "Epoch 2/30\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7448 - loss: 0.7277 - val_accuracy: 0.7634 - val_loss: 0.6907\n",
            "Epoch 3/30\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7519 - loss: 0.6953 - val_accuracy: 0.7736 - val_loss: 0.6791\n",
            "Epoch 4/30\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.7605 - loss: 0.6710 - val_accuracy: 0.7718 - val_loss: 0.6682\n",
            "Epoch 5/30\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7662 - loss: 0.6621 - val_accuracy: 0.7858 - val_loss: 0.6442\n",
            "Epoch 6/30\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7681 - loss: 0.6546 - val_accuracy: 0.7850 - val_loss: 0.6317\n",
            "Epoch 7/30\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7756 - loss: 0.6296 - val_accuracy: 0.7782 - val_loss: 0.6500\n",
            "Epoch 8/30\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.7780 - loss: 0.6324 - val_accuracy: 0.7754 - val_loss: 0.6798\n",
            "Epoch 9/30\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.7844 - loss: 0.6041 - val_accuracy: 0.7898 - val_loss: 0.6204\n",
            "Epoch 10/30\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.7872 - loss: 0.5933 - val_accuracy: 0.7954 - val_loss: 0.6122\n",
            "Epoch 11/30\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7880 - loss: 0.5981 - val_accuracy: 0.7928 - val_loss: 0.6300\n",
            "Epoch 12/30\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7876 - loss: 0.5935 - val_accuracy: 0.7710 - val_loss: 0.6887\n",
            "Epoch 13/30\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7951 - loss: 0.5785 - val_accuracy: 0.7950 - val_loss: 0.6194\n",
            "Epoch 14/30\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8010 - loss: 0.5693 - val_accuracy: 0.7948 - val_loss: 0.6314\n",
            "Epoch 15/30\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8019 - loss: 0.5558 - val_accuracy: 0.7834 - val_loss: 0.6331\n",
            "Epoch 16/30\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8053 - loss: 0.5484 - val_accuracy: 0.7950 - val_loss: 0.6070\n",
            "Epoch 17/30\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8068 - loss: 0.5456 - val_accuracy: 0.7968 - val_loss: 0.6233\n",
            "Epoch 18/30\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8081 - loss: 0.5442 - val_accuracy: 0.7952 - val_loss: 0.6075\n",
            "Epoch 19/30\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8113 - loss: 0.5324 - val_accuracy: 0.7996 - val_loss: 0.6013\n",
            "Epoch 20/30\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8093 - loss: 0.5309 - val_accuracy: 0.7934 - val_loss: 0.6143\n",
            "Epoch 21/30\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8142 - loss: 0.5187 - val_accuracy: 0.7980 - val_loss: 0.6124\n",
            "Epoch 22/30\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8134 - loss: 0.5266 - val_accuracy: 0.8026 - val_loss: 0.6062\n",
            "Epoch 23/30\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8224 - loss: 0.5050 - val_accuracy: 0.7804 - val_loss: 0.6594\n",
            "Epoch 24/30\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8141 - loss: 0.5242 - val_accuracy: 0.8012 - val_loss: 0.6027\n",
            "Epoch 25/30\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8211 - loss: 0.5040 - val_accuracy: 0.8046 - val_loss: 0.6023\n",
            "Epoch 26/30\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8205 - loss: 0.5049 - val_accuracy: 0.8066 - val_loss: 0.6136\n",
            "Epoch 27/30\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8236 - loss: 0.4963 - val_accuracy: 0.7740 - val_loss: 0.7226\n",
            "Epoch 28/30\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8158 - loss: 0.5169 - val_accuracy: 0.8008 - val_loss: 0.6342\n",
            "Epoch 29/30\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8302 - loss: 0.4868 - val_accuracy: 0.8046 - val_loss: 0.5946\n",
            "Epoch 30/30\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8249 - loss: 0.4926 - val_accuracy: 0.7996 - val_loss: 0.6207\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(f\"Test Loss: {test_loss}\")\n",
        "print(f\"Test Accuracy: {test_accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tEBjpkFusM9B",
        "outputId": "e7e2fabc-6567-4469-e03b-cd1e95f18e4d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.6591309905052185\n",
            "Test Accuracy: 0.7824000120162964\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model with more filters in convolutional layers\n",
        "inputs = Input(shape=(32, 32, 3))\n",
        "\n",
        "# Block 1\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
        "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "x = Dropout(0.25)(x)\n",
        "\n",
        "# Block 2\n",
        "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "x = Dropout(0.25)(x)\n",
        "\n",
        "# Block 3\n",
        "x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "x = Dropout(0.25)(x)\n",
        "\n",
        "# Fully connected layers\n",
        "x = Flatten()(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "outputs = Dense(10, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "E11AY3CxtBFP"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train, y_train, validation_split=0.1, epochs=40, batch_size=64, verbose=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AI6FtuVWtDUU",
        "outputId": "70a4c693-196f-4524-b32c-d31b2dd0b4b2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 15ms/step - accuracy: 0.3005 - loss: 1.8827 - val_accuracy: 0.5700 - val_loss: 1.2112\n",
            "Epoch 2/40\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.5520 - loss: 1.2475 - val_accuracy: 0.6682 - val_loss: 0.9488\n",
            "Epoch 3/40\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.6260 - loss: 1.0524 - val_accuracy: 0.6920 - val_loss: 0.9128\n",
            "Epoch 4/40\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.6713 - loss: 0.9355 - val_accuracy: 0.7386 - val_loss: 0.7589\n",
            "Epoch 5/40\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.6976 - loss: 0.8587 - val_accuracy: 0.7294 - val_loss: 0.8005\n",
            "Epoch 6/40\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.7204 - loss: 0.7980 - val_accuracy: 0.7416 - val_loss: 0.7377\n",
            "Epoch 7/40\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7371 - loss: 0.7553 - val_accuracy: 0.7616 - val_loss: 0.6913\n",
            "Epoch 8/40\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7474 - loss: 0.7202 - val_accuracy: 0.7540 - val_loss: 0.7206\n",
            "Epoch 9/40\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7541 - loss: 0.6942 - val_accuracy: 0.7754 - val_loss: 0.6546\n",
            "Epoch 10/40\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7682 - loss: 0.6513 - val_accuracy: 0.7764 - val_loss: 0.6564\n",
            "Epoch 11/40\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.7820 - loss: 0.6138 - val_accuracy: 0.7680 - val_loss: 0.7031\n",
            "Epoch 12/40\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.7847 - loss: 0.6130 - val_accuracy: 0.7828 - val_loss: 0.6452\n",
            "Epoch 13/40\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8005 - loss: 0.5682 - val_accuracy: 0.7804 - val_loss: 0.6516\n",
            "Epoch 14/40\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8006 - loss: 0.5690 - val_accuracy: 0.7908 - val_loss: 0.6274\n",
            "Epoch 15/40\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8093 - loss: 0.5442 - val_accuracy: 0.7684 - val_loss: 0.6816\n",
            "Epoch 16/40\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.8111 - loss: 0.5312 - val_accuracy: 0.7914 - val_loss: 0.6155\n",
            "Epoch 17/40\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8142 - loss: 0.5173 - val_accuracy: 0.8006 - val_loss: 0.6047\n",
            "Epoch 18/40\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8231 - loss: 0.5005 - val_accuracy: 0.7982 - val_loss: 0.6045\n",
            "Epoch 19/40\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.8270 - loss: 0.4872 - val_accuracy: 0.8032 - val_loss: 0.6114\n",
            "Epoch 20/40\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8253 - loss: 0.4937 - val_accuracy: 0.8054 - val_loss: 0.6038\n",
            "Epoch 21/40\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8349 - loss: 0.4637 - val_accuracy: 0.8066 - val_loss: 0.5998\n",
            "Epoch 22/40\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.8374 - loss: 0.4610 - val_accuracy: 0.8026 - val_loss: 0.5944\n",
            "Epoch 23/40\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.8443 - loss: 0.4406 - val_accuracy: 0.8032 - val_loss: 0.6084\n",
            "Epoch 24/40\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.8463 - loss: 0.4436 - val_accuracy: 0.8030 - val_loss: 0.6152\n",
            "Epoch 25/40\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.8484 - loss: 0.4341 - val_accuracy: 0.8042 - val_loss: 0.6006\n",
            "Epoch 26/40\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.8486 - loss: 0.4301 - val_accuracy: 0.8110 - val_loss: 0.5807\n",
            "Epoch 27/40\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.8496 - loss: 0.4193 - val_accuracy: 0.8006 - val_loss: 0.6062\n",
            "Epoch 28/40\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.8604 - loss: 0.4003 - val_accuracy: 0.8046 - val_loss: 0.6199\n",
            "Epoch 29/40\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.8532 - loss: 0.4195 - val_accuracy: 0.8066 - val_loss: 0.6166\n",
            "Epoch 30/40\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.8564 - loss: 0.4125 - val_accuracy: 0.8074 - val_loss: 0.6512\n",
            "Epoch 31/40\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.8623 - loss: 0.3924 - val_accuracy: 0.8088 - val_loss: 0.6024\n",
            "Epoch 32/40\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.8610 - loss: 0.3959 - val_accuracy: 0.8158 - val_loss: 0.5966\n",
            "Epoch 33/40\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.8658 - loss: 0.3836 - val_accuracy: 0.8106 - val_loss: 0.6151\n",
            "Epoch 34/40\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8661 - loss: 0.3809 - val_accuracy: 0.8020 - val_loss: 0.6458\n",
            "Epoch 35/40\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8659 - loss: 0.3853 - val_accuracy: 0.8080 - val_loss: 0.6140\n",
            "Epoch 36/40\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8674 - loss: 0.3763 - val_accuracy: 0.8128 - val_loss: 0.6209\n",
            "Epoch 37/40\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.8756 - loss: 0.3612 - val_accuracy: 0.8100 - val_loss: 0.6224\n",
            "Epoch 38/40\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.8724 - loss: 0.3621 - val_accuracy: 0.8122 - val_loss: 0.6294\n",
            "Epoch 39/40\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8721 - loss: 0.3658 - val_accuracy: 0.8202 - val_loss: 0.6212\n",
            "Epoch 40/40\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.8791 - loss: 0.3449 - val_accuracy: 0.8162 - val_loss: 0.5879\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model with an extra convolutional block\n",
        "inputs = Input(shape=(32, 32, 3))\n",
        "\n",
        "# Block 1\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
        "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "x = Dropout(0.25)(x)\n",
        "\n",
        "# Block 2\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "x = Dropout(0.25)(x)\n",
        "\n",
        "# Block 3\n",
        "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "x = Dropout(0.25)(x)\n",
        "\n",
        "# Block 4 (new block)\n",
        "x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "x = Dropout(0.25)(x)\n",
        "\n",
        "# Fully connected layers\n",
        "x = Flatten()(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "outputs = Dense(10, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-4RcCRyJuWXY"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train, y_train, validation_split=0.1, epochs=40, batch_size=64, verbose=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWn6L1mlvfJ7",
        "outputId": "b9711656-a97f-42bf-ae65-b51cf09664c6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 14ms/step - accuracy: 0.2673 - loss: 1.9454 - val_accuracy: 0.5160 - val_loss: 1.3189\n",
            "Epoch 2/40\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.5122 - loss: 1.3456 - val_accuracy: 0.6142 - val_loss: 1.0996\n",
            "Epoch 3/40\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.5894 - loss: 1.1582 - val_accuracy: 0.6696 - val_loss: 0.9418\n",
            "Epoch 4/40\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6334 - loss: 1.0413 - val_accuracy: 0.6732 - val_loss: 0.9250\n",
            "Epoch 5/40\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.6570 - loss: 0.9617 - val_accuracy: 0.6542 - val_loss: 1.0061\n",
            "Epoch 6/40\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6780 - loss: 0.9082 - val_accuracy: 0.7244 - val_loss: 0.7803\n",
            "Epoch 7/40\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6935 - loss: 0.8688 - val_accuracy: 0.7210 - val_loss: 0.8020\n",
            "Epoch 8/40\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7086 - loss: 0.8267 - val_accuracy: 0.7396 - val_loss: 0.7444\n",
            "Epoch 9/40\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7139 - loss: 0.8071 - val_accuracy: 0.7470 - val_loss: 0.7271\n",
            "Epoch 10/40\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7215 - loss: 0.7814 - val_accuracy: 0.7642 - val_loss: 0.7042\n",
            "Epoch 11/40\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7287 - loss: 0.7772 - val_accuracy: 0.7346 - val_loss: 0.7519\n",
            "Epoch 12/40\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7337 - loss: 0.7533 - val_accuracy: 0.7658 - val_loss: 0.6713\n",
            "Epoch 13/40\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7414 - loss: 0.7364 - val_accuracy: 0.7574 - val_loss: 0.7129\n",
            "Epoch 14/40\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7495 - loss: 0.7078 - val_accuracy: 0.7314 - val_loss: 0.7558\n",
            "Epoch 15/40\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7517 - loss: 0.7040 - val_accuracy: 0.7392 - val_loss: 0.7538\n",
            "Epoch 16/40\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7546 - loss: 0.6937 - val_accuracy: 0.7640 - val_loss: 0.6902\n",
            "Epoch 17/40\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7584 - loss: 0.6889 - val_accuracy: 0.7728 - val_loss: 0.6648\n",
            "Epoch 18/40\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.7646 - loss: 0.6653 - val_accuracy: 0.7534 - val_loss: 0.7101\n",
            "Epoch 19/40\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7678 - loss: 0.6622 - val_accuracy: 0.7714 - val_loss: 0.6595\n",
            "Epoch 20/40\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7671 - loss: 0.6629 - val_accuracy: 0.7818 - val_loss: 0.6231\n",
            "Epoch 21/40\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7692 - loss: 0.6474 - val_accuracy: 0.7778 - val_loss: 0.6588\n",
            "Epoch 22/40\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7690 - loss: 0.6485 - val_accuracy: 0.7846 - val_loss: 0.6440\n",
            "Epoch 23/40\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7770 - loss: 0.6420 - val_accuracy: 0.7818 - val_loss: 0.6476\n",
            "Epoch 24/40\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7787 - loss: 0.6284 - val_accuracy: 0.7826 - val_loss: 0.6507\n",
            "Epoch 25/40\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7808 - loss: 0.6181 - val_accuracy: 0.7844 - val_loss: 0.6469\n",
            "Epoch 26/40\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7789 - loss: 0.6274 - val_accuracy: 0.7888 - val_loss: 0.6387\n",
            "Epoch 27/40\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.7812 - loss: 0.6188 - val_accuracy: 0.7786 - val_loss: 0.6553\n",
            "Epoch 28/40\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7837 - loss: 0.6160 - val_accuracy: 0.7852 - val_loss: 0.6461\n",
            "Epoch 29/40\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7853 - loss: 0.6196 - val_accuracy: 0.7900 - val_loss: 0.6213\n",
            "Epoch 30/40\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7867 - loss: 0.6048 - val_accuracy: 0.7844 - val_loss: 0.6398\n",
            "Epoch 31/40\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7874 - loss: 0.6119 - val_accuracy: 0.7936 - val_loss: 0.6140\n",
            "Epoch 32/40\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.7941 - loss: 0.5874 - val_accuracy: 0.7926 - val_loss: 0.6205\n",
            "Epoch 33/40\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7907 - loss: 0.5934 - val_accuracy: 0.7984 - val_loss: 0.6010\n",
            "Epoch 34/40\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7975 - loss: 0.5802 - val_accuracy: 0.7784 - val_loss: 0.6779\n",
            "Epoch 35/40\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7943 - loss: 0.5832 - val_accuracy: 0.7966 - val_loss: 0.6001\n",
            "Epoch 36/40\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7935 - loss: 0.5900 - val_accuracy: 0.7926 - val_loss: 0.6296\n",
            "Epoch 37/40\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7992 - loss: 0.5724 - val_accuracy: 0.8032 - val_loss: 0.6006\n",
            "Epoch 38/40\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7999 - loss: 0.5693 - val_accuracy: 0.7934 - val_loss: 0.6194\n",
            "Epoch 39/40\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7985 - loss: 0.5812 - val_accuracy: 0.7930 - val_loss: 0.6597\n",
            "Epoch 40/40\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7972 - loss: 0.5742 - val_accuracy: 0.7776 - val_loss: 0.6874\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model with smaller kernel sizes\n",
        "inputs = Input(shape=(32, 32, 3))\n",
        "\n",
        "# Block 1\n",
        "x = Conv2D(32, (2, 2), activation='relu', padding='same')(inputs)\n",
        "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "x = Dropout(0.25)(x)\n",
        "\n",
        "# Block 2\n",
        "x = Conv2D(64, (2, 2), activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "x = Dropout(0.25)(x)\n",
        "\n",
        "# Block 3\n",
        "x = Conv2D(128, (2, 2), activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "x = Dropout(0.25)(x)\n",
        "\n",
        "# Fully connected layers\n",
        "x = Flatten()(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "outputs = Dense(10, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "jQ3wYNboxHwC"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train, y_train, validation_split=0.1, epochs=10, batch_size=64, verbose=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2A0cl1gxMaz",
        "outputId": "e16f38c7-5c25-46c8-dc2a-32f0920cd29d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - accuracy: 0.2754 - loss: 1.9583 - val_accuracy: 0.5116 - val_loss: 1.4012\n",
            "Epoch 2/10\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4875 - loss: 1.4238 - val_accuracy: 0.5582 - val_loss: 1.2472\n",
            "Epoch 3/10\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.5489 - loss: 1.2588 - val_accuracy: 0.6218 - val_loss: 1.0618\n",
            "Epoch 4/10\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5882 - loss: 1.1496 - val_accuracy: 0.6480 - val_loss: 1.0155\n",
            "Epoch 5/10\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6117 - loss: 1.0853 - val_accuracy: 0.6684 - val_loss: 0.9459\n",
            "Epoch 6/10\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.6321 - loss: 1.0343 - val_accuracy: 0.6908 - val_loss: 0.9012\n",
            "Epoch 7/10\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.6483 - loss: 0.9895 - val_accuracy: 0.6756 - val_loss: 0.9384\n",
            "Epoch 8/10\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6655 - loss: 0.9450 - val_accuracy: 0.7016 - val_loss: 0.8586\n",
            "Epoch 9/10\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6694 - loss: 0.9240 - val_accuracy: 0.7306 - val_loss: 0.8020\n",
            "Epoch 10/10\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6860 - loss: 0.8826 - val_accuracy: 0.7212 - val_loss: 0.8049\n"
          ]
        }
      ]
    }
  ]
}